{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/p.bushipaka/conda/envs/coreset/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm\n",
    "from config import Config2\n",
    "from template import LLAMA3_CHAT_TEMPLATE\n",
    "from typing import Dict, Tuple\n",
    "from peft import PeftModel\n",
    "from utils import read_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a2e11c",
   "metadata": {},
   "source": [
    "### Details to run\n",
    "\n",
    "- First run a warm up model (ascent.py, sim_vanilla.py), check all the requirements,path correctly, model_id, adaptor_id.\n",
    "- Check your data setup. this can be confusing, if you run all the setups.\n",
    "- Calculate the representations \n",
    "- Calculate the shift, need to do again for another model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0605991",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'data_setup_1' #change this accordingly\n",
    "df = pd.read_file('./data/full_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'path to the finetuned model, which is basically pre unlearning model'\n",
    "adaptor_id = 'your warm up model path'\n",
    "algorithm ='gd' # or snpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae621ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_id,  device_map = \"auto\", torch_dtype=torch.bfloat16)\n",
    "model = PeftModel.from_pretrained(base_model, adaptor_id, device_map=\"auto\", torch_dtype=torch.bfloat16) \n",
    "model = model.merge_and_unload()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79b6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_mean(\n",
    "    df, model, tokenizer, device, batch_size=1,\n",
    "    exclude_special_tokens: bool = True,\n",
    "    max_length: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a (N, H) array of mean-pooled penultimate-layer embeddings.\n",
    "    - Pools over non-padding tokens (attention_mask==1).\n",
    "    - If exclude_special_tokens=True, removes BOS/CLS/EOS/etc. from the average.\n",
    "    \"\"\"\n",
    "    texts = (df['question_f'] + df['answer_f']).tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    model.eval()\n",
    "    print('Now extracting mean-pooled hidden reps')\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            max_length=max_length,\n",
    "            return_special_tokens_mask=True  # needed to optionally drop specials\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        # (B, T, H)\n",
    "        penultimate = outputs.hidden_states[-2]\n",
    "\n",
    "        # Build mask: start from attention_mask (exclude padding)\n",
    "        # Shape: (B, T, 1)\n",
    "        mask = inputs['attention_mask'].unsqueeze(-1)\n",
    "\n",
    "        if exclude_special_tokens and 'special_tokens_mask' in inputs:\n",
    "            # special_tokens_mask: 1 for special tokens -> set them to 0 in our pooling mask\n",
    "            specials = inputs['special_tokens_mask'].unsqueeze(-1)\n",
    "            mask = mask * (1 - specials)\n",
    "\n",
    "        # Avoid division by zero in rare degenerate cases\n",
    "        lengths = mask.sum(dim=1).clamp(min=1)  # (B, 1)\n",
    "\n",
    "        # Mean pool\n",
    "        summed = (penultimate * mask).sum(dim=1)          # (B, H)\n",
    "        mean_pooled = (summed / lengths).float().cpu().numpy()  # (B, H)\n",
    "\n",
    "        all_embeddings.append(mean_pooled)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "def get_reps_mean(df, model, tokenizer, device, batch_size=1, **kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper that returns a dataframe with a 'representation' column\n",
    "    containing mean-pooled embeddings.\n",
    "    kwargs are passed to get_hidden_states_mean.\n",
    "    \"\"\"\n",
    "    embeddings = get_hidden_states_mean(\n",
    "        df=df, model=model, tokenizer=tokenizer, device=device,\n",
    "        batch_size=batch_size, **kwargs\n",
    "    )\n",
    "    annotated_df = df.copy()\n",
    "    annotated_df['representation_mean'] = list(embeddings)\n",
    "    return annotated_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202e0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_template_format(df):\n",
    "     df['question_f'] = df['question'].apply(lambda x : LLAMA3_CHAT_TEMPLATE.format(question = x))\n",
    "     df['answer_f'] = df['answer'].apply(lambda x : x + tokenizer.eos_token)  \n",
    "     return df\n",
    "\n",
    "df = make_template_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for pre unlearning representations\n",
    "\n",
    "df = get_reps_mean(df=df, model=base_model, tokenizer=tokenizer, device=torch.device('cuda'), batch_size=16)\n",
    "representations = np.stack(df['representation_mean'].values)\n",
    "np.save('./reps/pre_ul_reps.npy', representations) # save this where you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96778271",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is for adaptor representations\n",
    "\n",
    "df = get_reps_mean(df=df, model=model, tokenizer=tokenizer, device=torch.device('cuda'), batch_size=16)\n",
    "representations = np.stack(df['representation_mean'].values)\n",
    "np.save(f'./reps/{ds}_{algorithm}_reps.npy', representations) # save this where you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724e3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retain_sets(df, n_forget, k_values=[1, 2, 5], strategy='orthogonal'):\n",
    "    \"\"\"\n",
    "    df: The dataframe with 'shift_score'\n",
    "    n_forget: Size of the forget set (98)\n",
    "    k_values: Multipliers [1, 2, 5]\n",
    "    strategy: 'orthogonal' (lowest shift) or 'hard' (highest shift) or 'random'\n",
    "    \"\"\"\n",
    "    sets = {}\n",
    "    \n",
    "    # Sort the dataframe once\n",
    "    if strategy == 'orthogonal':\n",
    "        # Sort ascending (Smallest shift first) -> Safest\n",
    "        sorted_df = df.sort_values(by='shift_score', ascending=True)\n",
    "    elif strategy == 'hard':\n",
    "        # Sort descending (Largest shift first) -> Most Protective\n",
    "        sorted_df = df.sort_values(by='shift_score', ascending=False)\n",
    "    elif strategy == 'random':\n",
    "        sorted_df = df.sample(frac=1, random_state=42) # Shuffle\n",
    "        \n",
    "    for k in k_values:\n",
    "        count = n_forget * k\n",
    "        selected_samples = sorted_df.head(count)\n",
    "        sets[f'k{k}'] = selected_samples\n",
    "        print(f\"Strategy: {strategy} | k={k} | Count: {len(selected_samples)}\")\n",
    "        print(f\"  -> Mean Shift: {selected_samples['shift_score'].mean():.4f}\")\n",
    "        \n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a45aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift_score(df):\n",
    "    matrix_pre = np.array(df['pre_ul'].tolist())\n",
    "    matrix_post = np.array(df['post_ul'].tolist())\n",
    "    diff_matrix = matrix_post - matrix_pre\n",
    "    df['shift_score'] = np.linalg.norm(diff_matrix, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23386a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retain_shift_score(df, retain_path):\n",
    "    retain = read_file(retain_path)\n",
    "    print('retain shape is: ', retain.shape)\n",
    "    retain_ids = retain['id'].tolist()\n",
    "    retain_shift = df.loc[df['id'].isin(retain_ids)]\n",
    "    return retain_shift\n",
    "\n",
    "def get_forget_shift_score(df, forget_path):\n",
    "    forget = read_file(forget_path)\n",
    "    print('forget shape is: ', forget.shape)\n",
    "    forget_ids = forget['id'].tolist()\n",
    "    forget_shift = df.loc[df['id'].isin(forget_ids)]\n",
    "    return forget_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20eb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## please check if you are loading the correct representation files (dataset and model wise)\n",
    "\n",
    "pre_ul_reps = np.load('./reps/pre_ul_reps.npy')\n",
    "post_ul_reps = np.load('./reps/{ds}_{algorithm}_reps.npy')\n",
    "\n",
    "df['pre_ul'] = list(pre_ul_reps)\n",
    "df['post_ul'] = list(post_ul_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_shift_score(df)\n",
    "retain_shift = get_retain_shift_score(df, f'./data/datasets/retain_1.parquet') #check the path retain_1, retain_2 etc based on your data setup\n",
    "forget_shift = get_forget_shift_score(df, './data/datasets/forget_1.parquet') #check the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad972e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "n =  len(forget_shift) * k\n",
    "\n",
    "retain_sets_ortho = get_retain_sets(retain_shift, n_forget=n, strategy='orthogonal') \n",
    "retain_sets_hard = get_retain_sets(retain_shift, n_forget=n, strategy='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_ortho = retain_sets_ortho['k1']\n",
    "k2_ortho = retain_sets_ortho['k2']\n",
    "k5_ortho = retain_sets_ortho['k5']\n",
    "\n",
    "k1_hard = retain_sets_hard['k1']\n",
    "k2_hard = retain_sets_hard['k2']\n",
    "k5_hard = retain_sets_hard['k5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8514caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1_ortho.to_parquet(f'{ds}_gd_ortho_1.parquet', index = False)\n",
    "k2_ortho.to_parquet(f'{ds}_gd_ortho_2.parquet', index = False)\n",
    "k5_ortho.to_parquet(f'{ds}_gd_ortho_5.parquet', index = False)\n",
    "\n",
    "\n",
    "k1_hard.to_parquet(f'{ds}_gd_hard_1.parquet', index = False)\n",
    "k2_hard.to_parquet(f'{ds}_gd_hard_2.parquet', index = False)\n",
    "k5_hard.to_parquet(f'{ds}_gd_hard_5.parquet', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreset",
   "language": "python",
   "name": "coreset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
