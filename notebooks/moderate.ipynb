{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd0e1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_hidden_states(df, model, tokenizer, device, batch_size=1, max_length = 512):\n",
    "    texts = (df['question_f'] + ' ' + df['answer_f']).tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    model.eval()\n",
    "    print('Now extracting hidden reps')\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding = True,\n",
    "            truncation = True,\n",
    "            return_tensors = 'pt',\n",
    "            max_length = max_length\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        penultimate_hidden_states = outputs.hidden_states[-2]\n",
    "\n",
    "        seq_lens = inputs['attention_mask'].sum(dim=-1) - 1\n",
    "\n",
    "        batch_size_curr = penultimate_hidden_states.shape[0]\n",
    "\n",
    "        last_token_embeddings = penultimate_hidden_states[\n",
    "            torch.arange(batch_size_curr, device = model.device),\n",
    "            seq_lens\n",
    "        ].float().cpu().numpy()\n",
    "        all_embeddings.append(last_token_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "def get_reps(\n",
    "    df, model, tokenizer, device, batch_size=1):\n",
    "    \n",
    "    embeddings = get_hidden_states(df = df, model = model, tokenizer = tokenizer, device = device, batch_size = batch_size)\n",
    "\n",
    "    annotated_df = df.copy()\n",
    "\n",
    "    annotated_df['representation'] = list(embeddings)\n",
    "\n",
    "    return annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab07438",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_and_select_mod(\n",
    "    annotated_df:pd.DataFrame,\n",
    "    selection_percent : float,\n",
    "    n_clusters:int,\n",
    "    represent_col:str = 'representation'):\n",
    "\n",
    "    if not (0 < selection_percent <= 1.0):\n",
    "        raise ValueError(\"selection_percent must be between 0 and 1\")\n",
    "    \n",
    "    if len(annotated_df) < n_clusters:\n",
    "        raise ValueError(\"n_clusters must be less than the number of rows in df\")\n",
    "\n",
    "    embeddings = np.vstack(annotated_df[represent_col].tolist())\n",
    "\n",
    "    kmeans = KMeans(n_clusters = n_clusters, random_state = 42, n_init = 'auto')\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    cluster_df = annotated_df.copy()\n",
    "    cluster_df['cluster'] = cluster_labels\n",
    "\n",
    "\n",
    "    # selecting samples closest to the median distance in each cluster\n",
    "\n",
    "    selected_indices = []\n",
    "    total_samples_to_select = int(len(cluster_df) * selection_percent)\n",
    "\n",
    "    print('Selecting samples closest to the median distance in each cluster...')\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        indices_in_cluster = np.where(cluster_labels == i)[0]\n",
    "        if len(indices_in_cluster) == 0:\n",
    "            continue\n",
    "\n",
    "        embeddings_in_cluster = embeddings[indices_in_cluster]\n",
    "        cluster_centroid  = centroids[i].reshape(1,-1)\n",
    "        distances = cdist(embeddings_in_cluster, cluster_centroid).flatten()\n",
    "        median_distance = np.median(distances)\n",
    "\n",
    "        distances_from_median = np.abs(distances - median_distance)\n",
    "        sorted_indices = indices_in_cluster[np.argsort(distances_from_median)]\n",
    "\n",
    "        proportion_of_cluster = len(indices_in_cluster) / len(cluster_df)\n",
    "        num_to_select_from_cluster = int(total_samples_to_select * proportion_of_cluster)\n",
    "        num_to_select_from_cluster = max(1, num_to_select_from_cluster) if len(indices_in_cluster) > 0 else 0\n",
    "\n",
    "        selected_indices.extend(sorted_indices[:num_to_select_from_cluster])\n",
    "    print(f\"Targeted {total_samples_to_select} samples, selected {len(selected_indices)}.\")\n",
    "    mod_df = cluster_df.iloc[selected_indices].copy()\n",
    "\n",
    "    return  cluster_df, mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d2e23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_template_format(df):\n",
    "     df['question_f'] = df['question'].apply(lambda x : LLAMA3_CHAT_TEMPLATE.format(question = x))\n",
    "     df['answer_f'] = df['answer'].apply(lambda x : x + tokenizer.eos_token)  \n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a63986",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_and_select_fixed(\n",
    "    annotated_df: pd.DataFrame,\n",
    "    total_samples: int,\n",
    "    n_clusters: int,\n",
    "    represent_col: str = 'representation'):\n",
    "    \"\"\"\n",
    "    Cluster embeddings and select a fixed number of samples closest to median distance.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    annotated_df : pd.DataFrame\n",
    "        DataFrame containing the representation column\n",
    "    total_samples : int\n",
    "        Total number of samples to select across all clusters\n",
    "    n_clusters : int\n",
    "        Number of clusters to create\n",
    "    represent_col : str\n",
    "        Column name containing the embeddings/representations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    cluster_df : pd.DataFrame\n",
    "        Original DataFrame with cluster labels added\n",
    "    mod_df : pd.DataFrame\n",
    "        Selected samples DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    if total_samples <= 0:\n",
    "        raise ValueError(\"total_samples must be greater than 0\")\n",
    "    \n",
    "    if total_samples > len(annotated_df):\n",
    "        raise ValueError(\"total_samples cannot exceed the number of rows in df\")\n",
    "    \n",
    "    if len(annotated_df) < n_clusters:\n",
    "        raise ValueError(\"n_clusters must be less than or equal to the number of rows in df\")\n",
    "\n",
    "    embeddings = np.vstack(annotated_df[represent_col].tolist())\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    cluster_df = annotated_df.copy()\n",
    "    cluster_df['cluster'] = cluster_labels\n",
    "\n",
    "    # Select samples closest to the median distance in each cluster\n",
    "    selected_indices = []\n",
    "    samples_per_cluster = total_samples // n_clusters\n",
    "    remainder = total_samples % n_clusters\n",
    "\n",
    "    print('Selecting samples closest to the median distance in each cluster...')\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        indices_in_cluster = np.where(cluster_labels == i)[0]\n",
    "        if len(indices_in_cluster) == 0:\n",
    "            continue\n",
    "\n",
    "        embeddings_in_cluster = embeddings[indices_in_cluster]\n",
    "        cluster_centroid = centroids[i].reshape(1, -1)\n",
    "        distances = cdist(embeddings_in_cluster, cluster_centroid).flatten()\n",
    "        median_distance = np.median(distances)\n",
    "\n",
    "        distances_from_median = np.abs(distances - median_distance)\n",
    "        sorted_indices = indices_in_cluster[np.argsort(distances_from_median)]\n",
    "\n",
    "        # Distribute remainder samples to first few clusters\n",
    "        num_to_select = samples_per_cluster + (1 if i < remainder else 0)\n",
    "        # Don't select more than available in cluster\n",
    "        num_to_select = min(num_to_select, len(indices_in_cluster))\n",
    "\n",
    "        selected_indices.extend(sorted_indices[:num_to_select])\n",
    "\n",
    "    print(f\"Targeted {total_samples} samples, selected {len(selected_indices)}.\")\n",
    "    print(f\"Samples per cluster: {samples_per_cluster}, with {remainder} clusters getting 1 extra sample.\")\n",
    "    \n",
    "    mod_df = cluster_df.iloc[selected_indices].copy()\n",
    "\n",
    "    return cluster_df, mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b77aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = load the data\n",
    "full_rep_df = get_reps(df=df, model=model, tokenizer=tokenizer, device=device, batch_size=1)\n",
    "cluster_df, moderate_1, = cluster_and_select_fixed(\n",
    "    annotated_df = df,\n",
    "    total_samples = 98,\n",
    "    n_clusters = 4,\n",
    "    represent_col = 'representation')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
