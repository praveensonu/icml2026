{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a443b61c",
   "metadata": {},
   "source": [
    "- You have to load the model, tokenizer, dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095138b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_el2n_scores(model, tokenizer, question, answer):\n",
    "    \n",
    "    templated_question = LLAMA3_CHAT_TEMPLATE.format(question = question)\n",
    "    prompt = f\"{templated_question}{answer}{tokenizer.eos_token}\"\n",
    "\n",
    "    # tokenize without the answer\n",
    "    inputs_no_answer = tokenizer(templated_question, return_tensors='pt').to(model.device)\n",
    "    full_input_ids_no_answer = inputs_no_answer.input_ids[0].tolist()\n",
    "\n",
    "    # tokenize with the answer\n",
    "    inputs_full = tokenizer(prompt, return_tensors = 'pt').to(model.device)\n",
    "    full_input_ids_full = inputs_full.input_ids[0].tolist()\n",
    "\n",
    "\n",
    "    # Find the start index of the answer tokens within the full prompt's token IDs\n",
    "    start_index = -1\n",
    "    min_len = min(len(full_input_ids_no_answer), len(full_input_ids_full))\n",
    "    for i in range(min_len):\n",
    "        if full_input_ids_no_answer[i] != full_input_ids_full[i]:\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index == -1 and len(full_input_ids_full) > len(full_input_ids_no_answer):\n",
    "        start_index = len(full_input_ids_no_answer)\n",
    "    elif start_index == -1:\n",
    "        print(f\"Warning: Could not find the start of the answer in the prompt for question: {question[:50]}...\")\n",
    "        print(\"Full Input IDs (Full):\", full_input_ids_full)\n",
    "        print(\"Full Input IDs (No Answer):\", full_input_ids_no_answer)\n",
    "        return 0.0\n",
    "\n",
    "    labels = inputs_full.input_ids.clone()\n",
    "    # Mask out tokens before the start of the answer\n",
    "    labels[0, :start_index] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**inputs_full, labels = labels)\n",
    "      logits = outputs.logits\n",
    "\n",
    "    logits_start_index = max(0, start_index - 1)\n",
    "    \n",
    "    logits_for_answer = logits[0, logits_start_index: -1, :]\n",
    "\n",
    "    labels_for_answer = labels[0, start_index: ]\n",
    "\n",
    "    valid_label_mask_answer = labels_for_answer != -100\n",
    "    valid_labels = labels_for_answer[valid_label_mask_answer]\n",
    "\n",
    "    if valid_labels.numel() == 0:\n",
    "\n",
    "      print(\"Warning: No valid labels found in the answer segment.\")\n",
    "      return 0.0\n",
    "    \n",
    "    valid_logits = logits_for_answer[valid_label_mask_answer]\n",
    "\n",
    "    if valid_logits.shape[0] != valid_labels.shape[0]:\n",
    "        print(\"Error: Mismatch between the number of valid logits and labels.\")\n",
    "        return 0.0\n",
    "    \n",
    "    probs = F.softmax(valid_logits, dim = -1)\n",
    "\n",
    "    one_hot_labels = F.one_hot(valid_labels, num_classes = probs.shape[-1]).float()\n",
    "\n",
    "    l2_norms = torch.norm(probs - one_hot_labels, p=2, dim=-1)\n",
    "\n",
    "    el2n_score = l2_norms.mean().item()\n",
    "\n",
    "    return el2n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb66c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_grand_data_top(percent_to_keep_top):\n",
    "    n_total = len(dataset)\n",
    "    start_index_top = n_total - int(n_total * percent_to_keep_top)\n",
    "    grand_top = dataset.select(range(start_index_top, n_total))\n",
    "    return grand_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d56f95",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/ds_1/retain_1.parquet')\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f51090",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "load the model and tokenizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bbe4bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "example_scores = []\n",
    "\n",
    "for example in dataset:\n",
    "    scores = get_el2n_scores(model, tokenizer, example['question'], example['answer'])\n",
    "    example_scores.append(scores)\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('el2n_score', example_scores)\n",
    "end_time = time.time() \n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
